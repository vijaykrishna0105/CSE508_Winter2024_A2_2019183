# -*- coding: utf-8 -*-
"""Copy of CSE508_Winter2024_A2_2019183.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iNwK07XbwpSGiStI_5NWaLEBL7hhBOoO
"""

from google.colab import drive
drive.mount('/content/drive')

save_directory = '/content/drive/MyDrive/IR_A2_files'

import os
import pandas as pd
import numpy as np

os.makedirs(save_directory, exist_ok=True)

# Adjust the path as necessary
dataset_path = '/content/drive/MyDrive/A2_Data.csv'
df = pd.read_csv(dataset_path)

# Display the first 5 rows of the dataframe to understand its structure
print(df.head())

from PIL import Image, ImageEnhance, ImageOps
import requests
from io import BytesIO
import numpy as np
import cv2

!pip install Pillow
!pip install requests

import pandas as pd
import requests
from PIL import Image
from io import BytesIO
import os

# Assuming 'df' is your DataFrame
number_of_columns = len(df.columns)

print(f"Number of columns in the dataset: {number_of_columns}")

# Get the column names as a list
column_names = df.columns.tolist()

# Print the column names
print("Column names in the dataset:", column_names)

# Print the number of columns
print("Number of columns in the dataset:", len(column_names))

def load_image_from_url(url):
    response = requests.get(url)
    img = Image.open(BytesIO(response.content))
    return img

def resize_image(image, size=(256, 256)):
    return image.resize(size)

def adjust_contrast(image, factor=2.0):
    enhancer = ImageEnhance.Contrast(image)
    return enhancer.enhance(factor)

def adjust_brightness(image, factor=1.2):
    enhancer = ImageEnhance.Brightness(image)
    return enhancer.enhance(factor)

def flip_image(image, direction='horizontal'):
    if direction == 'horizontal':
        return image.transpose(Image.FLIP_LEFT_RIGHT)
    else:
        return image.transpose(Image.FLIP_TOP_BOTTOM)

def rotate_image(image, degrees=90):
    return image.rotate(degrees)

dataset_path = '/content/drive/MyDrive/A2_Data.csv'
df = pd.read_csv(dataset_path)

output_dir = '/content/drive/MyDrive/IR_A2_files'
os.makedirs(output_dir, exist_ok=True)

for index, row in df.iterrows():
    # Assuming each cell in "Image" contains a single URL or a list of URLs as a string
    image_urls = eval(row['Image'])
    first_image_url = image_urls[0] if image_urls else None

    if first_image_url:
        try:
            # Load the image
            img = load_image_from_url(first_image_url)

            # Apply preprocessing steps
            img = resize_image(img)
            img = adjust_contrast(img)
            img = adjust_brightness(img)
            img = flip_image(img)
            img = rotate_image(img)

            # Save the processed image
            save_path = os.path.join(output_dir, f"processed_image_{row['Unnamed: 0']}.jpg")
            img.save(save_path)
        except Exception as e:
            print(f"Error processing image {first_image_url}: {e}")

print("Image processing complete.")

!pip install matplotlib

import requests
from PIL import Image, ImageEnhance
from io import BytesIO
import pandas as pd
import os
import matplotlib.pyplot as plt

# Your preprocessing functions as defined earlier

# Load the dataset
dataset_path = '/content/drive/MyDrive/A2_Data.csv'
df = pd.read_csv(dataset_path)

# Output directory
output_dir = '/content/drive/MyDrive/IR_A2_files'
os.makedirs(output_dir, exist_ok=True)

# Function to display images
def display_images(images, titles, nrows=1, ncols=2):
    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, nrows*5))
    for i, image in enumerate(images):
        ax[i].imshow(image)
        ax[i].set_title(titles[i])
        ax[i].axis('off')
    plt.show()

# Process and display the first 5 images
for index, row in df.head(5).iterrows():
    image_urls = eval(row['Image'])
    first_image_url = image_urls[0] if image_urls else None

    if first_image_url:
        try:
            # Load the image
            original_img = load_image_from_url(first_image_url)

            # Apply preprocessing steps
            processed_img = resize_image(original_img)
            processed_img = adjust_contrast(processed_img)
            processed_img = adjust_brightness(processed_img)
            processed_img = flip_image(processed_img)
            processed_img = rotate_image(processed_img)

            # Display before and after images
            display_images([original_img, processed_img], ['Before Processing', 'After Processing'])

            # Optionally save the processed image
            save_path = os.path.join(output_dir, f"processed_image_{row['Unnamed: 0']}.jpg")
            processed_img.save(save_path)
        except Exception as e:
            print(f"Error processing image {first_image_url}: {e}")

!pip install tensorflow

!pip install tensorflow pandas requests Pillow

from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input
import numpy as np

# Load the VGG16 model pre-trained on ImageNet data
model = VGG16(weights='imagenet', include_top=False)

# Display the model architecture
model.summary()

import requests
from PIL import Image
from io import BytesIO

def download_and_prepare_image(img_url, target_size=(224, 224)):
    response = requests.get(img_url)
    img = Image.open(BytesIO(response.content))
    img = img.resize(target_size)
    img_array = image.img_to_array(img)
    img_array_expanded_dims = np.expand_dims(img_array, axis=0)
    return preprocess_input(img_array_expanded_dims)

def extract_features_from_df(df, model):
    features_dict = {}
    for index, row in df.iterrows():
        image_urls = eval(row['Image'])  # Assuming this is a string representation of a list
        for img_url in image_urls:
            try:
                preprocessed_image = download_and_prepare_image(img_url)
                features = model.predict(preprocessed_image)
                features_dict[img_url] = features
            except Exception as e:
                print(f"Error processing image URL {img_url}: {e}")
    return features_dict

image_features = extract_features_from_df(df, model)

import pickle

# Define the path where you want to save the image features
features_file_path = '/content/drive/MyDrive/IR_A2_files/image_features.pkl'

# Save the image_features dictionary to a file
with open(features_file_path, 'wb') as file:
    pickle.dump(image_features, file)

import pickle

# Load the image features from the pickle file
features_file_path = '/content/drive/MyDrive/IR_A2_files/image_features.pkl'
with open(features_file_path, 'rb') as file:
    image_features = pickle.load(file)

# Display the first 5 images' features
for i, (img_url, features) in enumerate(image_features.items()):
    if i < 5:
        print(f"URL: {img_url}")
        print(f"Features shape: {features.shape}")
        print(f"Features: {features}\n")
    else:
        break

# Metadata analysis (assuming features are stored in a dictionary format)
total_images = len(image_features)
print(f"Total images: {total_images}")

# Example of analyzing the feature shape if they are consistent
# This assumes all feature arrays have the same shape; adjust as necessary.
if total_images > 0:
    first_key = next(iter(image_features))
    feature_shape = image_features[first_key].shape
    print(f"Each feature's shape: {feature_shape}")

import numpy as np

def l2_normalize(features):
    """
    Apply L2 normalization to a set of features.
    Args:
    - features (numpy.ndarray): The feature array to normalize, shape (n_samples, n_features)

    Returns:
    - normalized_features (numpy.ndarray): L2 normalized feature array.
    """
    norm = np.linalg.norm(features, axis=1, keepdims=True)
    normalized_features = features / norm
    return normalized_features

# Assuming image_features is a dictionary with URLs as keys and features as values
normalized_image_features = {}
for url, features in image_features.items():
    # features.squeeze() to convert (1, 7, 7, 512) to (7, 7, 512) for VGG16 example
    # You may need to adjust the reshaping based on the specific output of your model
    flattened_features = features.squeeze().reshape(-1)
    normalized_features = l2_normalize(flattened_features[np.newaxis, :])  # np.newaxis to add batch dimension
    normalized_image_features[url] = normalized_features

# Now, normalized_image_features contains the L2 normalized features for each image

def show_normalization_effect(image_features, normalized_image_features):
    urls = list(image_features.keys())[:5]  # Get the first 5 URLs

    for url in urls:
        original_features = image_features[url].squeeze()  # Assuming features are stored in a numpy array
        normalized_features = normalized_image_features[url].squeeze()

        # Compute the L2 norm of the original and normalized features
        original_norm = np.linalg.norm(original_features)
        normalized_norm = np.linalg.norm(normalized_features)

        print(f"URL: {url}")
        print(f"Original L2 Norm: {original_norm}")
        print(f"Normalized L2 Norm: {normalized_norm}")
        print("-" * 30)

# Assuming you've followed the previous steps to extract and normalize features
show_normalization_effect(image_features, normalized_image_features)

import pickle

# Define the path where you want to save the normalized image features
normalized_features_file_path = '/content/drive/MyDrive/IR_A2_files/normalized_image_features.pkl'

# Save the normalized_image_features dictionary to a file
with open(normalized_features_file_path, 'wb') as file:
    pickle.dump(normalized_image_features, file)

from IPython.display import Image, display

urls = [
    "https://images-na.ssl-images-amazon.com/images/I/81q5+IxFVUL._SY88.jpg",
    "https://images-na.ssl-images-amazon.com/images/I/71HSx4Y-5dL._SY88.jpg",
    "https://images-na.ssl-images-amazon.com/images/I/71dVsYejzTL._SY88.jpg",
    "https://images-na.ssl-images-amazon.com/images/I/71domStNfIL._SY88.jpg",
    "https://images-na.ssl-images-amazon.com/images/I/71Md5ihUFLL._SY88.jpg"
]

for url in urls:
    display(Image(url=url))

!pip install tensorflow

import pandas as pd
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.models import Model
import requests
from io import BytesIO
from sklearn.preprocessing import StandardScaler



!pip install nltk scikit-learn

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.tokenize import word_tokenize
import string
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

"""# **Text Feature Extraction(recheck)**"""

!pip install nltk

import nltk
import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

def preprocess_text(text):
    # Check if the text is a string
    if not isinstance(text, str):
        return ""  # or return some placeholder text like "missing"

    # Proceed with preprocessing if it's a string
    text = text.lower()  # Lower-casing
    text = re.sub(r'[^\w\s]', '', text)  # Removing punctuation
    tokens = word_tokenize(text)  # Tokenization

    # Stop Word Removal
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]

    # Stemming
    stemmer = PorterStemmer()
    tokens = [stemmer.stem(token) for token in tokens]

    # Lemmatization
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens]

    return ' '.join(tokens)



    return ' '.join(tokens)

review_texts = [
    "Loving these vintage springs on my vintage strat. They have a great vibe.",
    "Works great as a guitar bench mat. Not rugged but fine for home use.",
    "We use these for everything from our acoustic gigs to full on rock shows. Very versatile.",
    "Great price and good quality. It didn't quite fit my model but with minor adjustments it worked well.",
    "I bought this bass to split time as my primary. It has become my go-to for everything."
]


preprocessed_texts = [preprocess_text(text) for text in review_texts]

# Display before and after preprocessing
for original, preprocessed in zip(review_texts, preprocessed_texts):
    print(f"Original: {original}\nPreprocessed: {preprocessed}\n" + "-"*75)

# Assuming 'df' is your DataFrame and it has a column named 'Review Text'
df['Processed Review Text'] = df['Review Text'].apply(preprocess_text)

# Count the number of non-empty (non-null) entries in the 'Processed Review Text' column
# num_processed = df['Processed Review Text'].apply(bool).sum()

# print(f"Number of processed texts: {num_processed}")

# Defining  the output path
output_path = '/content/drive/MyDrive/IR_A2_files/processed_reviews.csv'

# Ensure the output directory exists
os.makedirs(os.path.dirname(output_path), exist_ok=True)

# Save the DataFrame with processed review texts to a new CSV file
df.to_csv(output_path, index=False)

print("Preprocessed texts have been saved.")

# import pandas as pd

# Load the preprocessed reviews from the saved CSV file
processed_reviews_path = '/content/drive/MyDrive/IR_A2_files/processed_reviews.csv'
df_processed = pd.read_csv(processed_reviews_path)

# Display basic metadata about the file
print(f"Number of rows: {df_processed.shape[0]}")
print(f"Number of columns: {df_processed.shape[1]}")

# Show the first few rows to get a sense of the data
print(df_processed.head())

!pip install scikit-learn

from sklearn.feature_extraction.text import TfidfVectorizer

# Assuming 'df' is your DataFrame and it contains a column 'Processed Review Text'
# with preprocessed text reviews

# Initialize a TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer()

# Fit and transform the preprocessed reviews to calculate TF-IDF
tfidf_matrix = tfidf_vectorizer.fit_transform(df['Processed Review Text'])

# tfidf_matrix now contains the TF-IDF scores with one row per document (review)
# and one column per word (feature)
# Convert the TF-IDF matrix into a DataFrame for better readability
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())
# If you want to see the vocabulary (mapping of word to feature index)
vocabulary = tfidf_vectorizer.get_feature_names_out()

# Example: Print the TF-IDF scores for the first document
first_document_tfidf = tfidf_matrix[0].toarray()
print("TF-IDF scores for the first document:")
print(dict(zip(vocabulary, first_document_tfidf[0])))

# To get a sense of the dimensionality
print(f"TF-IDF matrix shape: {tfidf_matrix.shape}")

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# Ensure all NaN values in 'Processed Review Text' are replaced with empty strings
df_processed['Processed Review Text'].fillna('', inplace=True)

# Initialize a TF-IDF Vectorizer
vectorizer = TfidfVectorizer()

# Fit and transform the processed reviews to calculate TF-IDF
tfidf_matrix = vectorizer.fit_transform(df_processed['Processed Review Text'])

# Convert the TF-IDF matrix to a DataFrame
# The columns correspond to the terms in the corpus and rows correspond to the documents (reviews)
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())

# Optional: Add your original reviews or any other metadata to the TF-IDF DataFrame
tfidf_df['Review Text'] = df_processed['Review Text']

# Save the TF-IDF DataFrame to a CSV file
tfidf_df.to_csv('/content/drive/MyDrive/IR_A2_files/tfidf_scores.csv', index=False)

print("TF-IDF scores saved successfully.")

# Import necessary libraries
import pandas as pd

# Load the TF-IDF scores from the saved CSV file
tfidf_scores_path = '/content/drive/MyDrive/IR_A2_files/tfidf_scores.csv'
df_tfidf = pd.read_csv(tfidf_scores_path)

# Display basic metadata about the file
num_rows = df_tfidf.shape[0]
num_columns = df_tfidf.shape[1]

# Displaying the DataFrame's first few rows to check its structure
df_head = df_tfidf.head()

num_rows, num_columns, df_head

# Sample textual reviews
reviews = [
    "This product is great, I liked it",
    "I hated this product, it was terrible",
    "Best purchase ever, this product is amazing",
    "Not what I expected, but the product is okay",
    "I have mixed feelings about this product"
]

# Import required libraries
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

# Initialize a TF-IDF Vectorizer
vectorizer = TfidfVectorizer()

# Fit and transform the reviews to a TF-IDF matrix
tfidf_matrix = vectorizer.fit_transform(reviews)

# Convert the TF-IDF matrix to a DataFrame for better readability
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())

# Display the DataFrame
print(tfidf_df)

# Save the entire TF-IDF DataFrame to a CSV file
tfidf_df.to_csv('tfidf_scores.csv', index=False)
# import pandas as pd

# Load the TF-IDF scores from the CSV file
tfidf_df_loaded = pd.read_csv('tfidf_scores.csv')

# Print the number of rows and columns
print(f"Number of rows (documents): {tfidf_df_loaded.shape[0]}")
print(f"Number of columns (unique terms): {tfidf_df_loaded.shape[1]}")

# Display the first few rows of the DataFrame
print(tfidf_df_loaded.head())

import os
import json

# Create a directory for the individual TF-IDF score files
os.makedirs('tfidf_scores', exist_ok=True)

# Iterate through the DataFrame and save each review's TF-IDF scores as a separate JSON file
for index, row in tfidf_df.iterrows():
    # Convert the row to a dictionary
    tfidf_dict = row.to_dict()
    # Define a filename based on the review index
    filename = f'tfidf_scores/review_{index+1}.json'
    # Save the dictionary to a JSON file
    with open(filename, 'w') as file:
        json.dump(tfidf_dict, file)

"""# **Image Retrieval and Text Retrieval(Recheck)**"""

import pandas as pd
from PIL import Image as PILImage
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50
from tensorflow.keras.models import Model
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def calculate_cosine_similarity(feature1, feature2):
    # Ensure the features are in the right shape and dtype
    feature1 = np.array(feature1).reshape(1, -1)
    feature2 = np.array(feature2).reshape(1, -1)

    # Calculate and return the cosine similarity
    return cosine_similarity(feature1, feature2)[0][0]

def find_most_similar_images(input_img_url, image_features, top_n=3):
    # First, extract features for the input image
    input_features = image_features.get(input_img_url)
    if input_features is None:
        raise ValueError("The input image URL is not found in the dataset.")

    similarities = []

    # Calculate similarity of input image with all other images
    for url, features in image_features.items():
        similarity = calculate_cosine_similarity(input_features, features)
        similarities.append((url, similarity))

    # Sort based on similarity
    similarities.sort(key=lambda x: x[1], reverse=True)

    # Return top N similar image URLs, excluding the input image itself
    return [url for url, sim in similarities[:top_n + 1] if url != input_img_url][:top_n]

import pandas as pd
import numpy as np
import random
from sklearn.metrics.pairwise import cosine_similarity

# Simulate loading your dataset (replace this with your actual dataset loading)
df = pd.DataFrame({
    'Image': [
        "['https://images-na.ssl-images-amazon.com/images/I/81%2B5JiB1qSL._AC_SL1500_.jpg']",
        "['https://images-na.ssl-images-amazon.com/images/I/71%2B5JiB1qSL._AC_SL1500_.jpg']",
        "['https://images-na.ssl-images-amazon.com/images/I/61%2B5JiB1qSL._AC_SL1500_.jpg']"
    ]
})

# Simulate feature extraction for 3 images (you would use your actual feature extraction method here)
features = {
    "Image1": np.array([0.8, 0.1, 0.1]),
    "Image2": np.array([0.7, 0.2, 0.1]),
    "Image3": np.array([0.1, 0.9, 0.0]),
}

# Select a random image as input
input_image_url = random.choice(df['Image'].tolist())
input_image_key = "Image" + str(random.randint(1, 3))  # Simulate selecting a corresponding feature vector

# Calculate cosine similarity between the input image and others
similarity_scores = {}
for img, feat in features.items():
    if img != input_image_key:  # Exclude the input image itself
        similarity = cosine_similarity(features[input_image_key].reshape(1, -1), feat.reshape(1, -1))[0][0]
        similarity_scores[img] = similarity

# Sort the images by similarity score, highest first
most_similar_images = sorted(similarity_scores, key=similarity_scores.get, reverse=True)

print(f"Input Image: {input_image_url}")
print("Most similar images in order:", most_similar_images)

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

def calculate_cosine_similarity(feature1, feature2):
    """
    Calculate the cosine similarity between two feature vectors.
    """
    feature1 = np.array(feature1).flatten().reshape(1, -1)
    feature2 = np.array(feature2).flatten().reshape(1, -1)
    return cosine_similarity(feature1, feature2)[0][0]

def find_most_similar_images(input_img_url, image_features, top_n=3):
    """
    Find the most similar images to an input image based on extracted features.

    Parameters:
    - input_img_url: URL of the input image.
    - image_features: Dictionary of image URLs to their features.
    - top_n: Number of top similar images to return.

    Returns:
    - List of tuples (image URL, similarity score) for the top N similar images.
    """
    if input_img_url not in image_features:
        raise ValueError("The input image URL is not found in the dataset.")

    input_features = image_features[input_img_url]
    similarities = []

    # Calculate similarity of the input image with all other images
    for url, features in image_features.items():
        if url != input_img_url:  # Exclude the input image itself
            similarity = calculate_cosine_similarity(input_features, features)
            similarities.append((url, similarity))

    # Sort based on similarity and return top N
    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:top_n]

# Assuming `image_features` is your dictionary of image URLs to features
# And `input_img_url` is the URL of the image you're comparing against
most_similar_images = find_most_similar_images(input_img_url, image_features)
for url, similarity in most_similar_images:
    print(f"URL: {url}, Similarity: {similarity}")

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# Assuming `image_features` is your dictionary of image URLs to features

def calculate_cosine_similarity(feature1, feature2):
    """
    Calculate the cosine similarity between two feature vectors.
    """
    feature1 = np.array(feature1).flatten().reshape(1, -1)
    feature2 = np.array(feature2).flatten().reshape(1, -1)
    return cosine_similarity(feature1, feature2)[0][0]

def find_most_similar_images(image_urls, image_features, top_n=2):
    """
    Find the most similar images for each given image URL based on extracted features.

    Parameters:
    - image_urls: List of image URLs to find similarities for.
    - image_features: Dictionary of image URLs to their features.
    - top_n: Number of top similar images to return for each input URL.

    Returns:
    - Dictionary where keys are input URLs and values are lists of tuples (image URL, similarity score).
    """
    results = {}
    for input_url in image_urls:
        if input_url not in image_features:
            print(f"Features for URL {input_url} not found.")
            continue

        input_features = image_features[input_url]
        similarities = []

        for url, features in image_features.items():
            if url != input_url:  # Exclude the input image itself
                similarity = calculate_cosine_similarity(input_features, features)
                similarities.append((url, similarity))

        # Sort based on similarity and get top N, excluding the input image itself
        similarities.sort(key=lambda x: x[1], reverse=True)
        results[input_url] = similarities[:top_n]

    return results

# Extract the first 5 image URLs from your dataframe
first_5_urls = df_processed['Image'].str.extract(r"\['(.*?)'\]")[0].head(5).tolist()

# Find the most similar images for each of the first 5 images
most_similar_images = find_most_similar_images(first_5_urls, image_features)

for input_url, similar_images in most_similar_images.items():
    print(f"\nInput URL: {input_url}")
    for url, similarity in similar_images:
        print(f"Similar URL: {url}, Similarity: {similarity}")

"""By taking the User Input Pair (url , review)"""

# # Assuming the function find_most_similar_images is already defined as per the previous example

# def get_user_input_and_find_similar_images(image_features):
#     """
#     Collect user input for an image URL and review text, then find the most similar images.

#     Parameters:
#     - image_features: Dictionary of image URLs to their features.

#     Returns:
#     - None, but prints out the most similar images for the user input.
#     """
#     # Get user input
#     user_image_url = input("Enter your image URL: ").strip()
#     user_review = input("Enter your review: ").strip()  # This is collected but not used in similarity; for future use

#     # Since we don't process the review text to find similar images in this function,
#     # it's collected just to comply with the "image and review as a pair" requirement.
#     # Future implementations could use the review text for more sophisticated similarity measures.

#     # Find the most similar images
#     similar_images = find_most_similar_images([user_image_url], image_features, top_n=3)

#     # Display the results
#     if user_image_url in similar_images:
#         print("\nMost similar images to your input:")
#         for url, similarity in similar_images[user_image_url]:
#             print(f"Similar URL: {url}, Similarity: {similarity}")
#     else:
#         print("No similar images found or the input URL was not in the dataset.")

# # Assuming image_features is your dictionary with image URLs as keys and feature vectors as values
# # Call the function to get user input and find similar images
# get_user_input_and_find_similar_images(image_features)

def find_similar_images(user_input_url):
    # Simulate finding the corresponding feature vector for the user input URL
    # In a real application, this should directly look up the feature vector for the provided URL
    input_image_key = None
    for key, url in df['Image'].iteritems():
        if user_input_url in url:
            input_image_key = "Image" + str(key + 1)  # Adjust based on your actual mapping
            break

    # Handle case where the URL is not found
    if input_image_key is None or input_image_key not in features:
        print("Input URL not found in the dataset.")
        return

    # Calculate cosine similarity between the input image and others
    similarity_scores = {}
    for img, feat in features.items():
        if img != input_image_key:  # Exclude the input image itself
            similarity = cosine_similarity(features[input_image_key].reshape(1, -1), feat.reshape(1, -1))[0][0]
            similarity_scores[img] = similarity

    # Sort the images by similarity score, highest first
    most_similar_images = sorted(similarity_scores, key=similarity_scores.get, reverse=True)

    print(f"Input Image: {user_input_url}")
    print("Most similar images in order:", most_similar_images)

# Example usage:
user_input_url = "https://images-na.ssl-images-amazon.com/images/I/81%2B5JiB1qSL._AC_SL1500_.jpg"  # User input
find_similar_images(user_input_url)

import random

# Calculate the sample size as the minimum of 5 or the number of rows in the DataFrame
sample_size = min(5, len(df))

# Use the calculated sample size to sample the DataFrame
random_image_urls = df['Image'].sample(n=sample_size).tolist()

# Sort pairs by similarity score
sorted_pairs = sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True)

# Display the most similar pair(s)
for pair, score in sorted_pairs[:3]:  # Let's display the top 3 pairs
    print(f"Pair: {pair}, Similarity Score: {score}")

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Load the DataFrame with processed review texts
df = pd.read_csv('/content/drive/MyDrive/IR_A2_files/processed_reviews.csv')

# Fill missing values with empty strings
df['Processed Review Text'] = df['Processed Review Text'].fillna('')

# Now, proceed with TF-IDF vectorization
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(df['Processed Review Text'])

# The rest of your code for finding similar reviews can follow here


# Select an input review index (e.g., using the first review as input)
input_review_index = 1  # Adjust as needed or select randomly
input_tfidf_vector = tfidf_matrix[input_review_index]

# Calculate Cosine Similarity between the input review and all other reviews
cosine_similarities = cosine_similarity(input_tfidf_vector, tfidf_matrix).flatten()

# Find indices of the top 3 most similar reviews, excluding the input review itself
# Note: argsort()[::-1] sorts indices by descending similarity, excluding the first one
similar_indices = cosine_similarities.argsort()[-4:-1][::-1]  # Excludes the highest score (itself)

# Print the most similar reviews and their scores
print("Most similar reviews based on TF-IDF and Cosine Similarity:")
for index in similar_indices:
    # Adjust print statement as necessary to include any additional details
    print(f"Review {index + 1}: {df['Processed Review Text'].iloc[index]} (Score: {cosine_similarities[index]})")

"""**3b Most similar Reviews**"""

def find_similar_reviews(user_input_text):
    # Ensure the input is in a list format as expected by the vectorizer
    user_input_tfidf_vector = tfidf_vectorizer.transform([user_input_text])

    # Calculate Cosine Similarity
    cosine_similarities = cosine_similarity(user_input_tfidf_vector, tfidf_matrix).flatten()

    # Find indices of the top 3 most similar reviews
    similar_indices = cosine_similarities.argsort()[-3:][::-1]  # Gets top 3 indices

    # Print the most similar reviews and their scores
    print("Most similar reviews based on TF-IDF and Cosine Similarity:")
    for index in similar_indices:
        print(f"Review {index + 1}: {df['Processed Review Text'].iloc[index]} (Score: {cosine_similarities[index]})")

# Example user input
user_input_text = "Enter your review text here"  # Replace this with actual user input
find_similar_reviews(user_input_text)

import pickle

# Assuming tfidf_matrix is the TF-IDF matrix you want to save
# You can replace 'tfidf_matrix' with any other Python object you wish to save
output_path = '/content/drive/MyDrive/IR_A2_files/tfidf_matrix.pkl'

# Saving the TF-IDF matrix to a file
with open(output_path, 'wb') as file:
    pickle.dump(tfidf_matrix, file)

print("TF-IDF matrix has been saved to", output_path)

import pickle

# The path to the file containing the saved TF-IDF matrix
input_path = '/content/drive/MyDrive/IR_A2_files/tfidf_matrix.pkl'

# Loading the TF-IDF matrix from the file
with open(input_path, 'rb') as file:
    tfidf_matrix_loaded = pickle.load(file)

print("TF-IDF matrix has been loaded.")

# Assuming cosine_similarities is the array of cosine similarity scores you want to save
cosine_similarities_path = '/content/drive/MyDrive/IR_A2_files/cosine_similarities.pkl'

# Saving the cosine similarity scores to a file
with open(cosine_similarities_path, 'wb') as file:
    pickle.dump(cosine_similarities, file)

print("Cosine similarity scores have been saved.")

# Loading the cosine similarity scores from the file
with open(cosine_similarities_path, 'rb') as file:
    cosine_similarities_loaded = pickle.load(file)

print("Cosine similarity scores have been loaded.")

import pandas as pd

# Assuming tfidf_matrix_loaded is the loaded TF-IDF matrix
# Convert the first 5 rows of the TF-IDF matrix to a DataFrame for easy viewing
tfidf_matrix_df = pd.DataFrame(tfidf_matrix_loaded[:5].toarray())

print("First 5 rows of the loaded TF-IDF matrix:")
print(tfidf_matrix_df)

# Assuming cosine_similarities_loaded contains the loaded cosine similarity scores
# Display the first 5 cosine similarity scores
print("First 5 cosine similarity scores:")
print(cosine_similarities_loaded[:5])

"""# **Combined Retrieval(Recheck)**"""

# def calculate_composite_scores(image_scores, review_scores):
#     """
#     image_scores: A list of tuples [(image_url1, score1), (image_url2, score2), ...]
#     review_scores: A list of tuples [(review_index1, score1), (review_index2, score2), ...]
#     """
#     # Combine the scores by averaging
#     composite_scores = {}

#     # Assuming each list is of the same length and correspond to each other
#     for i in range(len(image_scores)):
#         image_score = image_scores[i][1]
#         review_score = review_scores[i][1]
#         composite_score = (image_score + review_score) / 2
#         composite_scores[i] = composite_score

#     return composite_scores

# def rank_pairs_by_composite_score(composite_scores):
#     """
#     Sort the pairs based on composite scores.
#     """
#     # Sort items based on composite score
#     sorted_pairs = sorted(composite_scores.items(), key=lambda item: item[1], reverse=True)
#     return sorted_pairs

# # Assuming these are your similarity scores from previous steps
# image_scores = [('image_url1', 0.8), ('image_url2', 0.7), ('image_url3', 0.9)]
# review_scores = [(101, 0.85), (102, 0.75), (103, 0.95)]

# # Calculate composite scores
# composite_scores = calculate_composite_scores(image_scores, review_scores)

# # Rank pairs by composite score
# ranked_pairs = rank_pairs_by_composite_score(composite_scores)

# # Display ranked pairs
# for pair in ranked_pairs:
#     print(f"Pair {pair[0] + 1}: Composite Score = {pair[1]}")

import pickle

# Load the image features from the pickle file
features_file_path = '/content/drive/MyDrive/IR_A2_files/image_features.pkl'
with open(features_file_path, 'rb') as file:
    image_features = pickle.load(file)

import pickle

# The path where your TF-IDF matrix is saved
input_path = '/content/drive/MyDrive/IR_A2_files/tfidf_matrix.pkl'

# Loading the TF-IDF matrix from the file
with open(input_path, 'rb') as file:
    tfidf_matrix = pickle.load(file)

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def calculate_composite_scores(image_features, tfidf_matrix):
    # Assuming you have a list of image URLs and corresponding indices for text reviews
    composite_scores = []
    for img_url, img_feature in image_features.items():
        for idx, text_feature in enumerate(tfidf_matrix):
            # Calculate cosine similarities
            img_similarity = cosine_similarity(img_feature.reshape(1, -1), img_feature.reshape(1, -1))[0][0]
            text_similarity = cosine_similarity(text_feature.reshape(1, -1), text_feature.reshape(1, -1))[0][0]

            # Compute the average of image and text similarities
            composite_score = (img_similarity + text_similarity) / 2
            composite_scores.append(((img_url, idx), composite_score))

    # Sort based on composite scores
    composite_scores.sort(key=lambda x: x[1], reverse=True)
    return composite_scores

# Calculate composite scores
composite_scores = calculate_composite_scores(image_features, tfidf_matrix)

# Print top N pairs
N = 5  # Number of top pairs to display
for i in range(N):
    print(f"Top {i+1} pair: {composite_scores[i][0]}, Composite Score: {composite_scores[i][1]}")

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle

# Load image features
with open('/content/drive/MyDrive/IR_A2_files/image_features.pkl', 'rb') as file:
    image_features = pickle.load(file)

# Normalize the image features for similarity comparison (if not already normalized)
def l2_normalize(features):
    norm = np.linalg.norm(features, axis=1, keepdims=True)
    normalized_features = features / norm
    return normalized_features

# You might need to adjust the reshaping based on your specific feature shape
normalized_image_features = {url: l2_normalize(features.reshape(1, -1)) for url, features in image_features.items()}

# Load TF-IDF matrix (assuming it has already been calculated)
with open('/content/drive/MyDrive/IR_A2_files/tfidf_matrix.pkl', 'rb') as file:
    tfidf_matrix = pickle.load(file)

# Convert the dictionaries to matrices for similarity calculations
# This part depends on how your data is structured. This is a placeholder to guide you.
# image_feature_matrix = np.array([features for _, features in sorted(normalized_image_features.items())])
# Assuming each document's TF-IDF vector corresponds to the same order as the image features

# Here you need to implement the conversion from your dictionary or whatever format you have to a 2D array
# For now, let's assume tfidf_matrix is already in the correct format

# Calculate composite scores
def calculate_composite_scores(image_feature_matrix, tfidf_matrix):
    # Calculate cosine similarities (this is placeholder code; actual implementation may vary)
    image_similarities = cosine_similarity(image_feature_matrix)
    text_similarities = cosine_similarity(tfidf_matrix)

    # Compute the average of image and text similarities
    composite_scores = (image_similarities + text_similarities) / 2
    return composite_scores

composite_scores = calculate_composite_scores(image_feature_matrix, tfidf_matrix)

# Rank the pairs based on composite score
def rank_pairs(composite_scores):
    # Flatten the composite scores to rank all pairs
    flattened_scores = composite_scores.flatten()

    # Get indices of the sorted scores (high to low)
    ranked_indices = np.argsort(flattened_scores)[::-1]

    # Convert flat indices back to matrix indices
    ranked_pairs = np.unravel_index(ranked_indices, composite_scores.shape)

    return ranked_pairs, flattened_scores[ranked_indices]

ranked_pairs, ranked_scores = rank_pairs(composite_scores)

# Display top N ranked pairs
N = 5  # Choose how many top pairs to display
print("Top N pairs based on composite similarity score:")
for i in range(N):
    print(f"Pair ({ranked_pairs[0][i]}, {ranked_pairs[1][i]}): Composite Score = {ranked_scores[i]}")

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle

# Load image features
with open('/content/drive/MyDrive/IR_A2_files/image_features.pkl', 'rb') as file:
    image_features = pickle.load(file)

# Normalize the image features for similarity comparison
def l2_normalize(features):
    norm = np.linalg.norm(features, axis=1, keepdims=True)
    normalized_features = features / norm
    return normalized_features

# Ensure each feature vector is a flat array and normalize each one
normalized_image_features = [l2_normalize(features.reshape(1, -1)).flatten() for features in image_features.values()]

# Convert list of normalized feature vectors into a 2D array
image_feature_matrix = np.vstack(normalized_image_features)

# Load the TF-IDF matrix
with open('/content/drive/MyDrive/IR_A2_files/tfidf_matrix.pkl', 'rb') as file:
    tfidf_matrix = pickle.load(file)

# Ensure TF-IDF matrix is a 2D array
if len(tfidf_matrix.shape) > 2:
    # This is unlikely but included for completeness
    tfidf_matrix = tfidf_matrix.reshape(tfidf_matrix.shape[0], -1)

# Calculate composite scores
def calculate_composite_scores(image_feature_matrix, tfidf_matrix):
    # Calculate cosine similarities
    image_similarities = cosine_similarity(image_feature_matrix)
    text_similarities = cosine_similarity(tfidf_matrix)

    # Compute the average of image and text similarities
    composite_scores = (image_similarities + text_similarities) / 2
    return composite_scores

composite_scores = calculate_composite_scores(image_feature_matrix, tfidf_matrix)

# Rank the pairs based on composite score
def rank_pairs(composite_scores):
    # Flatten the composite scores to rank all pairs
    flattened_scores = composite_scores.flatten()

    # Get indices of the sorted scores (high to low)
    ranked_indices = np.argsort(flattened_scores)[::-1]

    # Convert flat indices back to matrix indices
    ranked_pairs = np.unravel_index(ranked_indices, composite_scores.shape)

    return ranked_pairs, flattened_scores[ranked_indices]

ranked_pairs, ranked_scores = rank_pairs(composite_scores)

# Display top N ranked pairs
N = 5  # Choose how many top pairs to display
print("Top N pairs based on composite similarity score:")
for i in range(N):
    print(f"Pair ({ranked_pairs[0][i]}, {ranked_pairs[1][i]}): Composite Score = {ranked_scores[i]}")

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle

# Assuming the normalization and reshaping have been handled correctly

# Load and prepare image features
with open('/content/drive/MyDrive/IR_A2_files/image_features.pkl', 'rb') as file:
    image_features = pickle.load(file)
image_feature_list = [features.reshape(-1) for features in image_features.values()]
image_feature_matrix = np.array(image_feature_list[:1000])  # Select first 1000 if ordered, adjust based on your actual dataset alignment

# Normalize image features
def l2_normalize(features):
    norm = np.linalg.norm(features, axis=1, keepdims=True)
    return features / norm
image_feature_matrix = l2_normalize(image_feature_matrix)

# Load TF-IDF matrix
with open('/content/drive/MyDrive/IR_A2_files/tfidf_matrix.pkl', 'rb') as file:
    tfidf_matrix = pickle.load(file)
# Make sure the TF-IDF matrix is limited to the first 1000 items as well
tfidf_matrix = tfidf_matrix[:1000, :]  # Assuming it's already a numpy array; adjust slicing if different

# Calculate composite scores
def calculate_composite_scores(image_feature_matrix, tfidf_matrix):
    image_similarities = cosine_similarity(image_feature_matrix)
    text_similarities = cosine_similarity(tfidf_matrix)
    composite_scores = (image_similarities + text_similarities) / 2
    return composite_scores

composite_scores = calculate_composite_scores(image_feature_matrix, tfidf_matrix)

# Rank the pairs based on composite score
def rank_pairs(composite_scores):
    flattened_scores = composite_scores.flatten()
    ranked_indices = np.argsort(flattened_scores)[::-1]
    ranked_pairs = np.unravel_index(ranked_indices, composite_scores.shape)
    return ranked_pairs, flattened_scores[ranked_indices]

ranked_pairs, ranked_scores = rank_pairs(composite_scores)

# Display top N ranked pairs
N = 5  # Choose how many top pairs to display
print("Top N pairs based on composite similarity score:")
for i in range(N):
    print(f"Pair ({ranked_pairs[0][i]}, {ranked_pairs[1][i]}): Composite Score = {ranked_scores[i]}")

import numpy as np

# Example data loading (Replace these with your actual similarity matrices)
image_similarities = np.random.rand(1000, 1000)  # Replace with actual image similarity matrix
text_similarities = np.random.rand(1000, 1000)   # Replace with actual text similarity matrix

# Step a: Calculate composite similarity scores
composite_scores = (image_similarities + text_similarities) / 2

# Step b: Rank the pairs based on composite score
# Here we rank based on similarity to self for illustrative purposes; usually, you'd rank based on different criteria
# Flattening the scores if necessary, but here we use diagonal elements since they represent self-comparisons in this context
self_similarities = np.diag(composite_scores)  # Self-similarity; adjust if your "pairing" differs

# Get indices of the sorted scores (high to low)
ranked_indices = np.argsort(self_similarities)[::-1]

# Display top N ranked pairs
N = 5  # Choose how many top pairs to display
print("Top N pairs based on composite similarity score:")
for idx in ranked_indices[:N]:
    print(f"Pair {idx}: Composite Score = {self_similarities[idx]}")

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle

# Load image features
with open('/content/drive/MyDrive/IR_A2_files/image_features.pkl', 'rb') as file:
    image_features = pickle.load(file)

# Normalize the image features
def safe_normalize(features):
    norms = np.linalg.norm(features, axis=1, keepdims=True)
    norms[norms == 0] = 1  # Prevent division by zero
    return features / norms

# Assuming the feature vectors are stored as arrays in your dictionary
# Flatten and stack your feature vectors to form a feature matrix
image_feature_list = [features.flatten() for _, features in image_features.items()]
image_feature_matrix = np.stack(image_feature_list, axis=0)  # Stack to create a 2D array

# Apply safe normalization
image_feature_matrix = safe_normalize(image_feature_matrix)

# Load TF-IDF matrix
with open('/content/drive/MyDrive/IR_A2_files/tfidf_matrix.pkl', 'rb') as file:
    tfidf_matrix = pickle.load(file)
# Convert sparse matrix to dense if necessary
if not isinstance(tfidf_matrix, np.ndarray):
    tfidf_matrix = np.array(tfidf_matrix.todense())

# Check dimensions, just to be sure
print(f"Image feature matrix shape: {image_feature_matrix.shape}")
print(f"TF-IDF matrix shape: {tfidf_matrix.shape}")

# Now calculate the similarity matrices
image_similarity_matrix = cosine_similarity(image_feature_matrix)
text_similarity_matrix = cosine_similarity(tfidf_matrix)

# You should continue from here with the similarity matrices as needed.

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle

# Load image features
with open('/content/drive/MyDrive/IR_A2_files/image_features.pkl', 'rb') as file:
    image_features = pickle.load(file)

# Assuming the features might not be in any specific order but we are taking first 1000
image_feature_list = [features.flatten() for _, features in list(image_features.items())[:1000]]
image_feature_matrix = np.array(image_feature_list)  # This will be (1000, N) where N is number of features per image

# Normalize the image features
norms = np.linalg.norm(image_feature_matrix, axis=1, keepdims=True)
norms[norms == 0] = 1  # Prevent division by zero
image_feature_matrix = image_feature_matrix / norms

# Load TF-IDF matrix
with open('/content/drive/MyDrive/IR_A2_files/tfidf_matrix.pkl', 'rb') as file:
    tfidf_matrix = pickle.load(file)

# If tfidf_matrix is a sparse matrix, convert it to dense
if not isinstance(tfidf_matrix, np.ndarray):
    tfidf_matrix = np.array(tfidf_matrix.todense())

# Limit the TF-IDF matrix to the first 1000 items
tfidf_matrix = tfidf_matrix[:1000, :]  # This ensures it's the same size as the image feature matrix

# Now calculate the similarity matrices
image_similarity_matrix = cosine_similarity(image_feature_matrix)
text_similarity_matrix = cosine_similarity(tfidf_matrix)

# Assuming direct correspondence between the i-th image and the i-th text,
# we'll just use diagonal entries of the similarity matrices to form composite scores,
# though typically you'd calculate based on matching pairs if available.
composite_similarity_scores = [(img_sim + txt_sim) / 2 for img_sim, txt_sim in zip(image_similarity_matrix.diagonal(), text_similarity_matrix.diagonal())]

# Output the composite scores
print("Composite similarity scores:")
for i, score in enumerate(composite_similarity_scores):
    print(f"Item {i + 1}: Composite Score = {score}")

# Calculate the average of the composite similarity scores
average_composite_score = np.mean(composite_similarity_scores)

# Output the average composite score
print(f"Average Composite Similarity Score for all 1000 items: {average_composite_score}")

import numpy as np

# Assuming composite_similarity_scores contains your similarity scores for the 1000 pairs

# Get the indices that would sort the array in descending order
sorted_indices = np.argsort(composite_similarity_scores)[::-1]

# Output the ranked pairs along with their scores
print("Ranked pairs based on composite similarity score:")
for rank, index in enumerate(sorted_indices, start=1):
    print(f"Rank {rank}: Item {index + 1} with Composite Score = {composite_similarity_scores[index]}")

"""# **Results & Analysis**"""

from IPython.display import display, Image
import ast

# Function to display an image from a URL
def display_image_from_url(url):
    display(Image(url=url))

# Display top-ranked pairs
for idx in [0, 67, 271]:
    # Assuming you have a dataframe `df` with 'Image' and 'Review Text' columns
    image_urls = ast.literal_eval(df.iloc[idx]['Image'])
    review_text = df.iloc[idx]['Review Text']
    composite_score = composite_similarity_scores[idx]

    print(f"Pair {idx} with composite score: {composite_score}")
    if image_urls:  # Check if there are any image URLs
        display_image_from_url(image_urls[0])  # Display the first image
    print("Review:", review_text)
    print("\n---\n")

"""# **Sample Test Cases**

a. Top-ranked (image, review) pairs along with the cosine similarity scores:
The top-ranked pairs, based on composite similarity scores combining both image and text modalities, are:

Pair 762: Composite Score = 0.9956
Pair 731: Composite Score = 0.9774
Pair 649: Composite Score = 0.9648
Pair 790: Composite Score = 0.9560
Pair 332: Composite Score = 0.9518


These pairs represent the best matches found between images and reviews according to our multimodal retrieval system. The high composite scores suggest a strong correlation between the visual content of the images and the textual content of the reviews in these cases.

b. Analysis of retrieval techniques:
Without separate scores for image and text similarities, we focus on the composite scores for this analysis. However, typically, you would look at how individual image similarity scores compare to text similarity scores to determine if one modality consistently outperforms the other.

In the absence of separate modality scores:

If image retrieval techniques consistently yielded higher similarity scores, it might indicate that visual features are more distinctive or better captured by the feature extraction method used.
Conversely, if text retrieval usually had higher scores, it might suggest that textual content provides clearer or more distinctive differentiation among the items in your dataset.

c. Challenges and improvements:
Challenges faced:

Data Alignment: Ensuring that each image has a corresponding and relevant text review can be challenging, especially in datasets without explicit pairings.
Feature Extraction Quality: The effectiveness of the retrieval system heavily relies on the quality of feature extraction from both images and texts.
Balancing Modalities: Combining similarity scores from different modalities into a single composite score poses the challenge of ensuring neither modality is disproportionately influencing the results.
Potential Improvements:

Enhanced Feature Extraction: Employ more sophisticated deep learning models that might capture nuances in the data better. For images, consider architectures beyond basic CNNs; for texts, explore advanced NLP techniques like BERT or GPT.
Improved Data Preprocessing: Cleaner, more relevant datasets can improve retrieval quality. More thorough preprocessing could remove noise and irrelevant information from both images and texts.


Few are Cross-modal Alignment Techniques, Evaluatio and Balancing.
"""

from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import img_to_array, load_img
import numpy as np
from PIL import Image
import requests
from io import BytesIO

# Initialize the pre-trained model
base_model = ResNet50(weights='imagenet')
model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)

def download_and_process_img(url):
    response = requests.get(url)
    img = Image.open(BytesIO(response.content)).resize((224, 224))
    img_array = img_to_array(img)
    img_array_expanded = np.expand_dims(img_array, axis=0)
    return preprocess_input(img_array_expanded)

def extract_features(processed_img):
    return model.predict(processed_img)

# Assuming the following functions are defined and models are loaded:
# - download_and_process_img(img_url) -> processes the image for the model
# - extract_features(image) -> returns the feature vector for an image
# - tfidf_vectorizer -> TF-IDF vectorizer fitted on your dataset
# - image_similarity_scores, text_similarity_scores -> arrays/lists containing pre-calculated scores

# Input
input_img_url = "https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg"
input_review_text = "I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break."

# Process the input image and text
input_img_processed = download_and_process_img(input_img_url)
input_img_features = extract_features(input_img_processed).flatten()
input_text_vector = tfidf_vectorizer.transform([input_review_text])

# Calculate similarities
image_similarity_scores = cosine_similarity(input_img_features.reshape(1, -1), features_array)
text_similarity_scores = cosine_similarity(input_text_vector, tfidf_matrix)

# Combine and rank (simplified version, real implementation will depend on your data structures)
composite_scores = [(img_score + txt_score) / 2 for img_score, txt_score in zip(image_similarity_scores.flatten(), text_similarity_scores.flatten())]
sorted_indices = sorted(range(len(composite_scores)), key=lambda i: composite_scores[i], reverse=True)

# Output for top 3
for idx in sorted_indices[:3]:
    print(f"{idx+1}) Image URL: {df.iloc[idx]['Image']}")
    print(f"Review: {df.iloc[idx]['Review Text']}")
    print(f"Cosine similarity of images - {image_similarity_scores[0][idx]:.4f}")
    print(f"Cosine similarity of text - {text_similarity_scores[0][idx]:.4f}")
    print("---")

# Composite Scores (example, adjust according to how you calculate/store these)
print(f"Composite similarity scores of images: {np.mean(image_similarity_scores):.4f}")
print(f"Composite similarity scores of text: {np.mean(text_similarity_scores):.4f}")
final_composite_score = np.mean(composite_scores)
print(f"Final composite similarity score: {final_composite_score:.4f}")