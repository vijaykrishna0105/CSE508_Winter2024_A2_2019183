# -*- coding: utf-8 -*-
"""CSE508_Winter2024_A2_2019183.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ONsJGGl2wmhMa4y1wFBSft3hK5wAhSEr
"""

from google.colab import drive
drive.mount('/content/drive')

save_directory = '/content/drive/MyDrive/IR_A2_files'

os.makedirs(save_directory, exist_ok=True)

!pip install tensorflow

import pandas as pd
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.models import Model
import requests
from io import BytesIO
from sklearn.preprocessing import StandardScaler

# Adjust the path as necessary
dataset_path = '/content/drive/MyDrive/A2_Data.csv'
df = pd.read_csv(dataset_path)

# Display the first 5 rows of the dataframe to understand its structure
print(df.head())



def download_and_process_img(url):
    response = requests.get(url)
    img = load_img(BytesIO(response.content), target_size=(224, 224))
    img_array = img_to_array(img)
    img_array_expanded = np.expand_dims(img_array, axis=0)
    return preprocess_input(img_array_expanded)

base_model = ResNet50(weights='imagenet')
model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)

# from PIL import UnidentifiedImageError

# for url in df['first_image_url']:
#     try:
#         if url:  # Check if URL is not None
#             processed_img = download_and_process_img(url)
#             features = model.predict(processed_img)
#             features_list.append(features.flatten())
#     except UnidentifiedImageError:
#         print(f"Failed to process image: {url}")
#         features_list.append(np.zeros((model.output.shape[1],)))  # Append zeros or handle otherwise

import ast  # For safely evaluating a string that contains a Python literal

# Function to extract the first URL from the 'Image' column
def extract_first_url(image_string):
    image_list = ast.literal_eval(image_string)  # Converts string to list
    if image_list:  # If the list is not empty
        return image_list[0]  # Return the first URL
    return None  # If the list is empty, return None

# Apply this function to each row in the 'Image' column
df['first_image_url'] = df['Image'].apply(extract_first_url)

features_list = []  # Initialize the list to store features

from PIL import UnidentifiedImageError

# Updated loop to process images from the 'first_image_url' column
for url in df['first_image_url']:
    try:
        if url:  # Check if URL is not None
            processed_img = download_and_process_img(url)
            features = model.predict(processed_img)
            features_list.append(features.flatten())
    except UnidentifiedImageError:
        print(f"Failed to process image: {url}")
        features_list.append(np.zeros((model.output.shape[1],)))  # Append zeros for missing or failed images

from sklearn.preprocessing import StandardScaler

# Convert features_list to a NumPy array for easier manipulation
features_array = np.array(features_list)

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit the scaler to your data and transform it
normalized_features = scaler.fit_transform(features_array)

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize the TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer()

# Assuming df['Review Text'] is already filled with empty strings for NaN values
text_features = tfidf_vectorizer.fit_transform(df['Review Text'])

# If you wish to normalize these text features as well:
# Use the same StandardScaler initialized before or create a new one for text features
scaler_text = StandardScaler(with_mean=False)  # with_mean=False to support sparse matrices
normalized_text_features = scaler_text.fit_transform(text_features)

# Fill NaN values with an empty string
df['Review Text'] = df['Review Text'].fillna('')

# Now, proceed with TF-IDF vectorization
text_features = tfidf_vectorizer.fit_transform(df['Review Text'])

# Continue with normalization if needed

"""## **Text Feature Extraction**"""

!pip install nltk scikit-learn

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.tokenize import word_tokenize
import string
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

def preprocess_text(text):
    # Lower-casing
    text = text.lower()

    # Tokenization
    tokens = word_tokenize(text)

    # Removing punctuation
    table = str.maketrans('', '', string.punctuation)
    stripped = [w.translate(table) for w in tokens]

    # Removing non-alphabetic tokens and stopwords
    words = [word for word in stripped if word.isalpha()]
    stop_words = set(stopwords.words('english'))
    words = [w for w in words if not w in stop_words]

    # Stemming/Lemmatization (optional, choose one)
    stemmer = PorterStemmer()
    lemmatizer = WordNetLemmatizer()
    stemmed = [stemmer.stem(word) for word in words]
    lemmatized = [lemmatizer.lemmatize(word) for word in words]

    # Choose stemmed or lemmatized for the final text
    return ' '.join(lemmatized)

df['processed_text'] = df['Review Text'].apply(preprocess_text)

tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_text'])

import pickle

# Assuming tfidf_matrix is your TF-IDF matrix and tfidf_vectorizer is the vectorizer
with open('/content/drive/MyDrive/tfidf_matrix.pkl', 'wb') as file:
    pickle.dump(tfidf_matrix, file)

with open('/content/drive/MyDrive/tfidf_vectorizer.pkl', 'wb') as file:
    pickle.dump(tfidf_vectorizer, file)

"""# **Image Retrieval and Text Retrieval**"""

from sklearn.metrics.pairwise import cosine_similarity
import pickle

import numpy as np
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.models import Model
import requests
from io import BytesIO

# Initialize the pre-trained model
base_model = ResNet50(weights='imagenet')
model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)

def download_and_process_img(url):
    response = requests.get(url)
    img = load_img(BytesIO(response.content), target_size=(224, 224))
    img_array = img_to_array(img)
    img_array_expanded = np.expand_dims(img_array, axis=0)
    return preprocess_input(img_array_expanded)

# Assuming 'Image' column contains image URLs
features_array = []  # This will store all the features

# for index, row in df.iterrows():
#     # Extract the URL from the 'Image' column. Adjust as necessary for your DataFrame structure
#     img_url = row['Image']
#     processed_img = download_and_process_img(img_url)
#     features = model.predict(processed_img)
#     features_array.append(features.flatten())

# features_array = np.array(features_array)  # Convert the list to a numpy array for easier handling

import ast  # Importing ast for safely converting string representations of lists to lists

features_list = []  # Initialize the list to store features

for index, row in df.iterrows():
    try:
        # Assuming 'Image' column contains a list in string format or a direct URL
        if isinstance(row['Image'], str) and row['Image'].startswith('['):
            img_urls = ast.literal_eval(row['Image'])
            img_url = img_urls[0] if img_urls else None
        else:
            img_url = row['Image']  # Direct URL case

        if img_url:  # If a URL is available
            processed_img = download_and_process_img(img_url)
            features = model.predict(processed_img)
            features_list.append(features.flatten())
        else:
            print(f"No valid URL found for row {index}")
            features_list.append(np.zeros((model.output.shape[1],)))  # Placeholder for missing or failed images

    except UnidentifiedImageError:
        print(f"Failed to process image at {img_url}")
        features_list.append(np.zeros((model.output.shape[1],)))  # Placeholder for errors

    except Exception as e:
        print(f"An error occurred for row {index}: {e}")
        features_list.append(np.zeros((model.output.shape[1],)))  # Placeholder for other errors

features_array = np.array(features_list)  # Convert the list to a numpy array

import ast
from sklearn.metrics.pairwise import cosine_similarity

# Process the first three images and find their features
input_features = []
for i in range(3):
    img_urls = ast.literal_eval(df.iloc[i]['Image'])
    if img_urls:  # Check if the list is not empty
        img_url = img_urls[0]  # Use the first URL
        processed_img = download_and_process_img(img_url)
        feature_vector = model.predict(processed_img)
        input_features.append(feature_vector)
    else:
        input_features.append(np.zeros((1, model.output.shape[1])))  # Placeholder for missing images

# Convert list of feature vectors to an array
input_features_array = np.vstack(input_features)

# Test with a single, known image URL
test_img_url = 'https://example.com/someimage.jpg'  # Replace with a valid image URL
processed_img = download_and_process_img(test_img_url)
features = model.predict(processed_img)
print(features.shape)

import ast

# Assuming 'df' is your dataframe and it's already loaded
# Convert the string representation of the list to an actual list and select the first URL
first_row_image_urls = ast.literal_eval(df.iloc[0]['Image'])
first_image_url = first_row_image_urls[0] if first_row_image_urls else None

if first_image_url:
    # Process the first image URL
    processed_img = download_and_process_img(first_image_url)
    features = model.predict(processed_img)
    print("Features shape:", features.shape)
else:
    print("No valid URL found in the first row.")

def download_and_process_img(url):
    try:
        response = requests.get(url)
        img = load_img(BytesIO(response.content), target_size=(224, 224))
        img_array = img_to_array(img)
        img_array_expanded = np.expand_dims(img_array, axis=0)
        return preprocess_input(img_array_expanded)
    except Exception as e:
        print(f"Error processing image URL {url}: {e}")
        return None

for index, row in df.iterrows():
    image_urls = ast.literal_eval(row['Image'])
    if image_urls:  # Ensure the list is not empty
        first_image_url = image_urls[0]
        processed_img = download_and_process_img(first_image_url)
        if processed_img is not None:
            features = model.predict(processed_img).flatten()
            features_list.append(features)
        else:
            print(f"Skipping image due to error: {first_image_url}")
            features_list.append(np.zeros((2048,)))  # Use a zero vector as a placeholder
    else:
        print("No image URL found in row, using placeholder.")
        features_list.append(np.zeros((2048,)))  # Placeholder for missing images

# Assuming the first image's features are your input features
input_features = features_list[0].reshape(1, -1)  # Reshape to 2D array for cosine_similarity function

# Convert your features_list to a NumPy array if you haven't yet
features_array = np.vstack(features_list)

# Calculate cosine similarity
cosine_sim = cosine_similarity(input_features, features_array)

# Get the indices of the top 3 most similar images, excluding the first one (itself)
# Use argsort to sort the similarity scores and get the indices
similar_indices = np.argsort(cosine_sim[0])[::-1][1:4]  # Skip the first one, take the next top 3

print("Indices of Top 3 Similar Images:", similar_indices)
for i in similar_indices:
    print("Image URL:", df.iloc[i]['Image'])
    print("Cosine Similarity Score:", cosine_sim[0][i])



from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Assuming `df['Review Text']` contains your review texts
reviews = df['Review Text'].values

# Step 1: Generate TF-IDF vectors
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(reviews)

# Choose an input review, here we take the first one as an example
input_review_vector = tfidf_vectorizer.transform([reviews[0]])

# Step 2: Calculate Cosine Similarity
cosine_similarities = cosine_similarity(input_review_vector, tfidf_matrix)

# Step 3: Rank and Retrieve Top Reviews
top_review_indices = np.argsort(cosine_similarities[0])[-4:]  # Exclude the first one which is the review itself
top_review_indices = top_review_indices[:-1][::-1]  # Get the top 3 indices, exclude the highest (itself)

print("Indices of Top 3 Similar Reviews:", top_review_indices)
for index in top_review_indices:
    print("Review:", reviews[index])
    print("Similarity Score:", cosine_similarities[0][index])

import pickle

# Example of saving the TF-IDF matrix
with open('tfidf_matrix.pkl', 'wb') as file:
    pickle.dump(tfidf_matrix, file)

# Example of loading the TF-IDF matrix
with open('tfidf_matrix.pkl', 'rb') as file:
    loaded_tfidf_matrix = pickle.load(file)

import os
print(os.getcwd())

import pickle

# Assuming tfidf_matrix and features_array are the objects you want to save
pickle.dump(tfidf_matrix, open(os.path.join(save_directory, 'tfidf_matrix.pkl'), 'wb'))
pickle.dump(features_array, open(os.path.join(save_directory, 'features_array.pkl'), 'wb'))

# Function to print first five entries of an object, adjusting based on the object's type
def print_first_five_entries(file_path):
    with open(file_path, 'rb') as file:
        obj = pickle.load(file)
        # Adjust this logic based on the structure of your object
        # Here's an example for a list or array-like object
        print(obj[:5])

# Paths to your saved files
tfidf_path = os.path.join(save_directory, 'tfidf_matrix.pkl')
features_path = os.path.join(save_directory, 'features_array.pkl')

# Print the first five entries
print("TF-IDF Matrix First Five Entries:")
print_first_five_entries(tfidf_path)

print("\nFeatures Array First Five Entries:")
print_first_five_entries(features_path)

"""# **Combined Retrieval**"""

# # Assuming image_similarity_scores and text_similarity_scores are lists or arrays of the same length
# composite_scores = [(img_score + txt_score) / 2 for img_score, txt_score in zip(image_similarity_scores, text_similarity_scores)]

# # Rank the pairs based on composite score
# # If you need to keep track of the original indices/pairs, consider using enumerate and sorting by score
# ranked_pairs_indices = sorted(range(len(composite_scores)), key=lambda i: composite_scores[i], reverse=True)

# # Now ranked_pairs_indices contains indices sorted by the highest composite score
# # Use these indices to retrieve or reference the original pairs

# # Example: Print top 3 ranked pairs
# print("Top 3 ranked pairs based on composite similarity score:")
# for idx in ranked_pairs_indices[:3]:
#     print(f"Pair {idx} with composite score: {composite_scores[idx]}")

# Recalculate the image similarity for demonstration
# Choose an input image features vector
input_image_features = features_array[0].reshape(1, -1)  # Example: Taking the first image's features

# Calculate cosine similarity for images
image_similarity_scores = cosine_similarity(input_image_features, features_array)[0]

# Assuming you have an input review's TF-IDF vector
# This would have been generated similar to how you processed all reviews into the tfidf_matrix
# For demonstration, let's assume it's the TF-IDF vector for the first review
input_review_vector = tfidf_matrix[0:1]

# Calculate cosine similarity for text
text_similarity_scores = cosine_similarity(input_review_vector, tfidf_matrix).flatten()

# Calculate composite scores by averaging image and text similarity scores
composite_scores = [(img_score + txt_score) / 2 for img_score, txt_score in zip(image_similarity_scores, text_similarity_scores)]

# Rank the pairs based on composite score
ranked_pairs_indices = sorted(range(len(composite_scores)), key=lambda i: composite_scores[i], reverse=True)

# Example: Print top 3 ranked pairs based on composite similarity score
print("Top 3 ranked pairs based on composite similarity score:")
for idx in ranked_pairs_indices[:3]:
    print(f"Pair {idx} with composite score: {composite_scores[idx]}")

from IPython.display import display, Image
import ast

# Function to display an image from a URL
def display_image_from_url(url):
    display(Image(url=url))

# Assuming `df` is your DataFrame
for idx in [0, 67, 271]:  # Example indices from your results
    print(f"Pair {idx} with composite score: {composite_scores[idx]}")
    row = df.iloc[idx]
    image_urls = ast.literal_eval(row['Image'])
    if image_urls:
        print("Displaying Image:")
        display_image_from_url(image_urls[0])
    print("Review:", row['Review Text'])
    print("\n---\n")

# Calculate composite similarity scores as the average of image and text similarity scores
composite_similarity_scores = [(img_score + text_score) / 2 for img_score, text_score in zip(image_similarity_scores, text_similarity_scores)]

# Example scores for demonstration; replace these with your actual similarity scores
# image_similarity_scores = [0.8, 0.5, 0.9]  # Example data
# text_similarity_scores = [0.7, 0.6, 0.4]   # Example data

# Calculate composite similarity scores as the average of image and text similarity scores
composite_similarity_scores = [(img_score + text_score) / 2 for img_score, text_score in zip(image_similarity_scores, text_similarity_scores)]

# Sort the indices of these scores in descending order to rank them from most to least similar
sorted_indices = sorted(range(len(composite_similarity_scores)), key=lambda i: composite_similarity_scores[i], reverse=True)

# Now, use sorted_indices to get the top N similar pairs
top_n = 3  # Adjust based on how many top pairs you'd like to retrieve
top_n_indices = sorted_indices[:top_n]

print(f"Top {top_n} similar pairs (based on composite similarity score):")
for idx in top_n_indices:
    print(f"Pair {idx} with composite score: {composite_similarity_scores[idx]}")
    # Optionally, display or process the corresponding image and text pair as needed

"""# **Results & Analysis**"""

from IPython.display import display, Image
import ast

# Function to display an image from a URL
def display_image_from_url(url):
    display(Image(url=url))

# Display top-ranked pairs
for idx in [0, 67, 271]:
    # Assuming you have a dataframe `df` with 'Image' and 'Review Text' columns
    image_urls = ast.literal_eval(df.iloc[idx]['Image'])
    review_text = df.iloc[idx]['Review Text']
    composite_score = composite_similarity_scores[idx]

    print(f"Pair {idx} with composite score: {composite_score}")
    if image_urls:  # Check if there are any image URLs
        display_image_from_url(image_urls[0])  # Display the first image
    print("Review:", review_text)
    print("\n---\n")

"""# **Sample Test Cases**"""

from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import img_to_array, load_img
import numpy as np
from PIL import Image
import requests
from io import BytesIO

# Initialize the pre-trained model
base_model = ResNet50(weights='imagenet')
model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)

def download_and_process_img(url):
    response = requests.get(url)
    img = Image.open(BytesIO(response.content)).resize((224, 224))
    img_array = img_to_array(img)
    img_array_expanded = np.expand_dims(img_array, axis=0)
    return preprocess_input(img_array_expanded)

def extract_features(processed_img):
    return model.predict(processed_img)

# Assuming the following functions are defined and models are loaded:
# - download_and_process_img(img_url) -> processes the image for the model
# - extract_features(image) -> returns the feature vector for an image
# - tfidf_vectorizer -> TF-IDF vectorizer fitted on your dataset
# - image_similarity_scores, text_similarity_scores -> arrays/lists containing pre-calculated scores

# Input
input_img_url = "https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg"
input_review_text = "I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break."

# Process the input image and text
input_img_processed = download_and_process_img(input_img_url)
input_img_features = extract_features(input_img_processed).flatten()
input_text_vector = tfidf_vectorizer.transform([input_review_text])

# Calculate similarities
image_similarity_scores = cosine_similarity(input_img_features.reshape(1, -1), features_array)
text_similarity_scores = cosine_similarity(input_text_vector, tfidf_matrix)

# Combine and rank (simplified version, real implementation will depend on your data structures)
composite_scores = [(img_score + txt_score) / 2 for img_score, txt_score in zip(image_similarity_scores.flatten(), text_similarity_scores.flatten())]
sorted_indices = sorted(range(len(composite_scores)), key=lambda i: composite_scores[i], reverse=True)

# Output for top 3
for idx in sorted_indices[:3]:
    print(f"{idx+1}) Image URL: {df.iloc[idx]['Image']}")
    print(f"Review: {df.iloc[idx]['Review Text']}")
    print(f"Cosine similarity of images - {image_similarity_scores[0][idx]:.4f}")
    print(f"Cosine similarity of text - {text_similarity_scores[0][idx]:.4f}")
    print("---")

# Composite Scores (example, adjust according to how you calculate/store these)
print(f"Composite similarity scores of images: {np.mean(image_similarity_scores):.4f}")
print(f"Composite similarity scores of text: {np.mean(text_similarity_scores):.4f}")
final_composite_score = np.mean(composite_scores)
print(f"Final composite similarity score: {final_composite_score:.4f}")